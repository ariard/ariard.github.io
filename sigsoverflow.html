<i> This post was initially sends for publication on the bitcoin-dev block ML 900708 - 2025-06-11 GMT </i><br>
<br>
Hi James, <br>
<br>
Thanks for your post. <br>
<br>
I think you can break the current version of CTV in the way it's currently proposed as a <br>
NOP refurbishment (i think OP_NOP4), which makes it a legacy script. <br>
<br>
Currently, there is a max limit of 80_000 sigops per-block (`MAX_BLOCK_SIGOPS_COST` <br>
in `src/consensus/consensus.h). That limit is applied for all legacy, p2sh and segwit <br>
scripts, at time of `Chainstate::ConnectBlock`: <br>
<br>
&nbsp;&nbsp;&nbsp;// GetTransactionSigOpCost counts 3 types of sigops: <br>
&nbsp;&nbsp;&nbsp;// * legacy (always) <br>
&nbsp;&nbsp;&nbsp;// * p2sh (when P2SH enabled in flags and excludes coinbase) <br>
&nbsp;&nbsp;&nbsp;// * witness (when witness enabled in flags and excludes coinbase) <br>
&nbsp;&nbsp;&nbsp;nSigOpsCost += GetTransactionSigOpCost(tx, view, flags); <br>
&nbsp;&nbsp;&nbsp;if (nSigOpsCost > MAX_BLOCK_SIGOPS_COST) { <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, "bad-blk-sigops", "too many sigops"); <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break; <br>
&nbsp;&nbsp;&nbsp;} <br>
<br>
This enforced limit means that any block with 80_001 signature operation <br>
within is going to be rejected by the receiving full-node ("too-many-sigops"). <br>
where a signature operation is any opcode like a CHECKSIG or CHECKMULTISIG <br>
(`GetSigOpCount()` in `src/script/script.h). <br>
<br>
While signature operations is not necessarily somehting you're going to think <br>
about when you design and deploy second-layers or contract protocol (even for <br>
coinpool we only make assumptions of 1000-sized off-chain constructions, so <br>
1000 sigs at max in the redeemscript), this signature operation limit is <br>
obviously weighted in by block template construction to ensure a valid block <br>
is generated by the network and not an insane amount of watt has been wasted. <br>
<br>
E.g, the default block template algorithm attached in core is using this limit: <br>
<br>
&nbsp;&nbsp;&nbsp;// TODO: switch to weight-based accounting for packages instead of vsize-based accounting. <br>
&nbsp;&nbsp;&nbsp;if (nBlockWeight + WITNESS_SCALE_FACTOR * packageSize >= m_options.nBlockMaxWeight) { <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return false; <br>
&nbsp;&nbsp;&nbsp;} <br>
&nbsp;&nbsp;&nbsp;if (nBlockSigOpsCost + packageSigOpsCost >= MAX_BLOCK_SIGOPS_COST) { <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return false; <br>
&nbsp;&nbsp;&nbsp;} <br>
&nbsp;&nbsp;&nbsp;return true; <br>
<br>
While it is well-established that many miners are running their own block <br>
construction algorithms, one can assume this limit exist for all while it's <br>
more unclear if they're selecting the highest feerate, *highest sigops* txn <br>
too. This selection of highest feerate, *highest sigops* block opens the door <br>
to an interesting exploitation for any use-cases with timelocks. <br>
<br>
Namely, let's say you have a use-case U which is locking funds in a redeem <br>
script S with path either alice_sig OR bob_timelock + bob_sig. Any adversary <br>
(i.e Bob) can fulfill the sequence of blocks from current chain tip leading <br>
up to bob_timelock to *censor* alice of redeeming the funds with high-feerate, <br>
high-sigops junk txn. <br>
<br>
Here a testcase on some bitcoin core 28.x branch doing so with empty CHECKMULTISIG <br>
as they have the highest ratio of sigops accounting per unit of feerate that one <br>
has to pay for: <br>
<br>
https://github.com/ariard/bitcoin/commit/b85a426c43cb7000788a55ea140b73a68da9ce4e <br>
<br>
A honest counterparty to the use-case U can indeed over-bid in feerate to get <br>
her legit time-sensitive tx confirming in block template over the adversary's junk. <br>
However, game-theory wise the counterparty is limited by the max amount of funds <br>
locked in the shared coins U. E.g if the use-case U has a weight unit surface of 20_000 <br>
WU and an amount of 100_000 satoshis, the honest counterparty will at most burn <br>
5 satoshis per WU. <br>
<br>
This is a clear limit that the adversary, who is a counterparty to the locked <br>
funds, can evaluate ahead and from then be break-even by finding N+1 use-case U <br>
of amount U or inferior where N is the timelock duration. <br>
<br>
While this "block sigops overflow" attacks present a lot of "maybe", most notably <br>
what is the txn selection algorithm for block template runned by the high-hashrate <br>
miners over the network, it's still put a wonder for any CTV use-case with a script <br>
of the following form: <br>
<br>
&nbsp;&nbsp;&nbsp;OP_IF <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;my_little_vault_hash OP_CTV&gt; <br>
&nbsp;&nbsp;&nbsp;OP_ELSE <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;alice_bob_their_family_aggregated_pubkey&gt; OP_CHECKSIG <br>
&nbsp;&nbsp;&nbsp;OP_ENDIF <br>
<br>
A simple upgrade can be to overhaul CTV design on top of a OP_SUCCESS or another <br>
tapscript upgrade paths, as tapscripts spends do not see their signature ops <br>
accounted in the per-block limit (BIP342 per-script sigops budget). The only <br>
way to further exploit would be inflate the txn spending the script, which should <br>
be correctly bounded by use-cases designers, I think. <br>
<br>
As far as I know, this problem has always been there since the activation of <br>
SegWit in 2017, and if I'm correct - but please don't trust, verify - the potential <br>
exposure of any shared UTXO with timelocks and competing interest has always been <br>
there...However, as far as I know this ill-design limit for time-sensitive use-cases <br>
has never been really been discussed among devs circlces and my own awareness of <br>
this problem is itself quite recent. <br>
<br>
That's all for the "letterocracy" and the ones who're currently thinking that <br>
covenant soft-forks are seriously technically reviewed... <br>
<br>
The only thing I'll add I'm still eager to review in good faith _both_ your <br>
proposal of CTV+CSFS and Poinsot's BIP54 in the future (in fine he's not personally <br>
responsible for what I did say on the BIP repos issue) in the future. <br>
<br>
If I'm correct on this "block sigops overflow" problem, there might be anyway <br>
things to re-think about, at least being sure we do not introduce new issues of <br>
this domain for current or upcoming use-cases. <br>
<br>
Best, <br>
Antoine "the evil one" <br>
OTS hash: 3598fa5db5a6f60639f938b58d85c2b563f4ff7728061eeb166998b7280287ce <br>
